\documentclass[Serif, 10pt, brown]{beamer}
\usepackage{booktabs,xcolor}
%\usepackage[svgnames,table]{xcolor}
%\usepackage[tableposition=above]{caption}
\usepackage{pifont}
\newcommand*\CHECK{\ding{51}}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
%
\usepackage{setspace,mathtools,amssymb,multirow,array,amsmath,tikz}
\usepackage[normalsize]{subfigure}
\usetikzlibrary{patterns}
\usetikzlibrary{automata,positioning,decorations.pathreplacing,decorations}

\usepackage{curves}
\usepackage{wasysym}
\usepackage{epsfig,epstopdf,graphicx}

\curvewarnfalse
%
\newtheorem{proposition}{Proposition}
\theoremstyle{example}
\newtheorem{theoremh}{Theorem}
\theoremstyle{plain}
\renewcommand{\textfraction}{0.01}
\renewcommand{\floatpagefraction}{0.99}
\newcommand{\ul}{\underline}
\newcounter{units}
%
%
\setbeamercovered{dynamic}
% Logo
\logo{\includegraphics[width=0.5in,keepaspectratio]{iitb_logo.png}}
%
% Setup
\mode<presentation>
	{
\usetheme[right,currentsection, hideothersubsections]{UTD}
			\useoutertheme{sidebar} \useinnertheme[shadow]{rounded}
			\usecolortheme{whale} \usecolortheme{orchid}
			\usefonttheme[onlymath]{serif}
			\setbeamertemplate{footline}{\centerline{Slide \insertframenumber/\inserttotalframenumber}}
	}
%
% Title
\usebeamercolor[fg]{author in sidebar}
\title[{CS349 Project}]{\sc Automatic Index Creation}
\author[\ul{Authors}]{{\bf { Saksham Rathi, Kavya Gupta, Shravan S, Mayank Kumar}}\\ {\footnotesize \hspace{0cm} (22B1003) \hspace{1cm} (22B1053) \hspace{0.5cm} (22B1054) \hspace{0.5cm} (22B0933)}}
\institute[UTD]{\sc\small CS349: DataBase and Information Systems\\ Under Prof. Sudarshan and Prof. Suraj}
\date[UCI]{Indian Institute of Technology Bombay \\ Spring 2024-25}
%
%Presentation
\begin{document}
\frame{\titlepage}
%
%
%Slides

%TOC

% \begin{frame}
% 	\transblindsvertical
% 	\frametitle{Contents}
% 	\tableofcontents[hidesubsections]
% \end{frame}

\section{Goals}
\begin{frame}{Goals of the project}
	\begin{itemize}
		\item Indexes are crucial for efficient query execution in relational databases.
		\item However, developers sometimes forget to create indexes for frequently queried columns.
		\item This can lead to repeated full relation scans, significantly degrading performance.
		\item {\bf Goal:} Modify the application layer of PostgreSQL to detect such patterns and automatically create indexes when beneficial \cite{nagesh2023indexes}.
		\item {\bf Another Goal} was to understand and implement the paper \textit{``An Auto-Indexing Technique for Databases Based on Clustering''} \cite{1333569}.
	\end{itemize}
\end{frame}

\section{What We Implemented From User Perspective}
\begin{frame}{What We Implemented From User Perspective}
	\begin{itemize}
		\item We implemented an interface that can take and submit queries from users as usual as well as automatically create (and remove) indices appropriately, thereby improving performance without any user intervention.
	\end{itemize}
\end{frame}

\section{What All Functionalities We Implemented}
\begin{frame}{What All Functionalities We Implemented}
	\begin{itemize}
		\item Developed a standalone C++ tool that takes SQL queries as input and performs real-time analysis.
		\item Implemented policy from the paper \textit{``An Auto-Indexing Technique for Databases Based on Clustering''} \cite{1333569}.
		\item The tool tracks attribute access frequencies and cost, and forks a background process to decide on index creation.
		\item Index creation is not based on fixed thresholds alone:
		\begin{itemize}
			\item It also invokes the PostgreSQL query planner to compare costs of executing the current query for different candidate indices.
			\item Index is created only if the cost savings are significant.
		\end{itemize}
		\item Also integrated removal of indices using 2 policies:
	\end{itemize}
\end{frame}

\section{How We Implemented It}
\begin{frame}{How We Implemented It – Part 1}
	\begin{itemize}
		\item Used the \texttt{pqxx} C++ library to connect and interact with PostgreSQL databases.
		\item Integrated the \texttt{sqlparse} Python library to parse complex SQL queries and extract attribute-level access details.
		\item Designed custom data structures to:
		\begin{itemize}
			\item Maintain per-query attribute access statistics.
			\item Track information about the existing (our tool made) indices.
		\end{itemize}
		\item Queries are handled online (i.e., one at a time), so query clustering was not required, unlike in batch-based approaches.
	\end{itemize}
\end{frame}

\begin{frame}{How We Implemented It – Part 2}
	\begin{itemize}
		\item \textbf{Candidate attribute selection} is based on the following condition:
		\vspace{-5pt}
		\[
		\texttt{Freq} > \texttt{threshold}_1 \quad \textbf{OR} \quad \texttt{Freq} \times T > \texttt{threshold}_2
		\vspace{-5pt}
		\]
		where:
		\begin{itemize}
			\item \texttt{Freq} = weighted frequency of attribute usage in past queries.
			\item \texttt{T} = number of rows in the table containing that attribute.
		\end{itemize}
		We fixed $\texttt{threshold}_1$ to be $10$. We took $\texttt{threshold}_2$ as the average of the size of all tables in the database (we change it every $50^{th}$ iteration).
	
		\item \textbf{Weighted frequency computation}:
		\begin{itemize}
			\item Weight = 3 if attribute is in \texttt{WHERE} clause.
			\item Weight = 2 if in \texttt{GROUP BY} or \texttt{ORDER BY}.
			\item Weight = 1 if used in an aggregate function (e.g., \texttt{SUM}, \texttt{COUNT}).
		\end{itemize}
		This helps prioritize attributes more critical to query performance.
	\end{itemize}
\end{frame}

\begin{frame}{How We Implemented It – Part 3}
	\begin{itemize}
		\item Once candidate indexable attributes are identified (via frequency and weights), we use the \textbf{\texttt{hypopg}} extension for final selection.
		
		\item \texttt{hypopg} allows us to:
		\begin{itemize}
			\item Create \textbf{hypothetical indexes} without modifying the database.
			\item Run the SQL query planner with these indexes as if they existed.
			\item Retrieve the estimated query execution cost from the planner.
		\end{itemize}
	
		\item This approach enables us to:
		\begin{itemize}
			\item Leverage PostgreSQL’s internal \textbf{statistics and heuristics}.
			\item Avoid wasting resources on ineffective indexes.
		\end{itemize}
	
		\item The top 50\% lowest cost of the candidate indices become the final indices and index is created for them in a child process (if not already).
	\end{itemize}
\end{frame}

\section{Conclusion and Future Work}
\begin{frame}{Conclusion and Future Work}
	\begin{itemize}
		\item We developed a real-time auto-indexing system that:
		\begin{itemize}
			\item Tracks attribute access patterns and frequencies.
			\item Applies a cost-aware filtering mechanism using PostgreSQL’s planner via \texttt{hypopg}.
			\item Automatically creates and removes indexes using adaptive policies.
		\end{itemize}
	
		\vspace{0.3cm}
		\item \textbf{Future Work:}
		\begin{itemize}
			\item Extend the system to handle batch workloads.
			\item Incorporate clustering of similar queries to identify shared indexable patterns.
			\item Explore reinforcement learning or predictive models for smarter index management.
		\end{itemize}
	\end{itemize}
	\end{frame}

\section{References}
\begin{frame}{References}
	\bibliographystyle{alpha}
    \bibliography{ref}
\end{frame}

\end{document}


